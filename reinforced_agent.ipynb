{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import namedtuple\n",
    "import math\n",
    "\n",
    "from kaggle_environments.envs.halite.helpers import ShipAction, Board\n",
    "from kaggle_environments import make\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as func\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ship_actions = [\n",
    "    ShipAction.NORTH, ShipAction.EAST, ShipAction.SOUTH,\n",
    "    ShipAction.WEST\n",
    "]\n",
    "BATCH_SIZE = 4\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "WINDOW_SIZE = 3\n",
    "\n",
    "Transitions = namedtuple(\n",
    "    'Transitions',\n",
    "    ['state', 'action', 'next_state', 'reward']\n",
    ")\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self):\n",
    "        self.data = {}\n",
    "        \n",
    "    def fit(self, X):\n",
    "        for idx, item in enumerate(X):\n",
    "            one_hot = torch.zeros(len(X), dtype=torch.int64)\n",
    "            one_hot[idx] = 1\n",
    "            self.data[item] = one_hot\n",
    "                    \n",
    "    def transform(self, item):\n",
    "        if isinstance(item, str):\n",
    "            return self.data[getattr(ShipAction, item)]\n",
    "        return self.data[item]\n",
    "    \n",
    "encoder = Encoder()\n",
    "encoder.fit(ship_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory:\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "    def push(self, state, action, next_state, reward):\n",
    "        if len(self) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transitions(\n",
    "            state=state, action=action, next_state=next_state,\n",
    "            reward=reward\n",
    "        )\n",
    "        self.position += 1\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(halites, ships, yards, size):\n",
    "    halites = torch.tensor(halites).reshape(size, size)\n",
    "    array_shape = WINDOW_SIZE * 2 + 1\n",
    "    ship_pos = torch.zeros((array_shape, array_shape))\n",
    "    yard_pos = torch.zeros((array_shape, array_shape))\n",
    "    halites_pos = torch.zeros((array_shape, array_shape))\n",
    "    \n",
    "    for ship_id, co_ord in ships.items():\n",
    "        x1, y1 = co_ord\n",
    "        for x in range(WINDOW_SIZE, -WINDOW_SIZE - 1, -1):\n",
    "            for y in range(-WINDOW_SIZE, WINDOW_SIZE + 1):\n",
    "                x_ = x + x1 if 0 < x + x1 < 21 else (x + x1) % 21\n",
    "                y_ = y + y1 if 0 < y + y1 < 21 else (y + y1) % 21\n",
    "                halites_pos[x + WINDOW_SIZE - 1][y + WINDOW_SIZE - 1] = halites[x_][y_]\n",
    "\n",
    "        for ship_id2, co_ord2 in ships.items():\n",
    "            x1_dash, y1_dash = co_ord2\n",
    "            ship_x = x1 - x1_dash + WINDOW_SIZE\n",
    "            ship_y = y1 - y1_dash + WINDOW_SIZE\n",
    "            ship_pos[ship_x][ship_y] = 1\n",
    "\n",
    "        for yard, yard_co_ord in yards.items():\n",
    "            x1_dash, y1_dash = yard_co_ord\n",
    "            yard_x = x1 - x1_dash + WINDOW_SIZE\n",
    "            yard_y = y1 - y1_dash + WINDOW_SIZE\n",
    "            yard_pos[yard_x][yard_y] = 1\n",
    "\n",
    "        \n",
    "        state = torch.stack([halites_pos, ship_pos, yard_pos])\n",
    "        x, y, z = state.size()\n",
    "        return state.reshape(1, x, y, z)\n",
    "    \n",
    "\n",
    "def agent(obs, config):\n",
    "    size = config.size\n",
    "    board = Board(obs, config)\n",
    "    me = board.current_player\n",
    "\n",
    "    ship_states = {}\n",
    "    yard_states = {}\n",
    "    exp_part = math.exp(config.steps/EPS_DECAY)\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * exp_part\n",
    "\n",
    "    sample = random.random()\n",
    "    for yard in me.shipyards:\n",
    "        yard_states[yard.id] = yard.position\n",
    "        \n",
    "    for ship in me.ships:\n",
    "        ship_states[ship.id] = ship.position\n",
    "\n",
    "    for ship in me.ships:\n",
    "        if sample > eps_threshold:\n",
    "            print(\"Predicting move\")\n",
    "            current_state = get_state(obs['halite'], ship_states, yard_states, size)\n",
    "            move = policy_net(current_state).argmax().item()\n",
    "            ship.next_action = ship_actions[move]\n",
    "        else:\n",
    "            print(\"random move\")\n",
    "            ship.next_action = random.choice(ship_actions)\n",
    "        \n",
    "    return me.next_actions, ship_states, yard_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepQNetwork(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (head): Linear(in_features=54, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, num_actions):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.head = nn.Linear(54, num_actions)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return self.head(x.view(x.size(0), -1))\n",
    "    \n",
    "\n",
    "policy_net = DeepQNetwork(len(ship_actions))\n",
    "target_net = DeepQNetwork(len(ship_actions))\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "\n",
    "\n",
    "def optimize_network():\n",
    "    if len(memory) > BATCH_SIZE:\n",
    "        batch = memory.sample(BATCH_SIZE)\n",
    "        batch = Transitions(*zip(*batch))\n",
    "        \n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.stack(batch.action).argmax(1).reshape(-1, 1)\n",
    "        reward_batch = torch.tensor(batch.reward)\n",
    "        next_states = torch.stack(batch.next_state)\n",
    "\n",
    "        state_action_values = policy_net(\n",
    "            state_batch).gather(1, action_batch)\n",
    "        next_state_values = target_net(next_states).max(1)[0].detach()\n",
    "        expected_state_action_values = (\n",
    "            next_state_values * GAMMA\n",
    "        ) + reward_batch\n",
    "        \n",
    "        loss = func.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ReplayMemory(1000)\n",
    "\n",
    "def train_loop():\n",
    "    env = make(\"halite\", debug=True)\n",
    "    trainer = env.train([None])\n",
    "    size = env.configuration.size\n",
    "    step = 0\n",
    "\n",
    "    for i in range(1):\n",
    "        observation = trainer.reset()\n",
    "        ship_states = {}\n",
    "        while not env.done:\n",
    "            env.configuration.steps = step\n",
    "            my_action, ships, yards = agent(observation,\n",
    "                                            env.configuration)\n",
    "            observation = trainer.step(my_action)[0]\n",
    "            halites = observation[\"halite\"]\n",
    "            halites = torch.tensor(halites).reshape(size, size)\n",
    "            array_shape = WINDOW_SIZE * 2 + 1\n",
    "            ship_pos = torch.zeros((array_shape, array_shape))\n",
    "            yard_pos = torch.zeros((array_shape, array_shape))\n",
    "            halites_pos = torch.zeros((array_shape, array_shape))\n",
    "            for ship_id, co_ord in ships.items():\n",
    "                x1, y1 = co_ord\n",
    "                for x in range(WINDOW_SIZE, -WINDOW_SIZE - 1, -1):\n",
    "                    for y in range(-WINDOW_SIZE, WINDOW_SIZE + 1):\n",
    "                        x_ = x + x1 if 0 < x + x1 < 21 else (x + x1) % 21\n",
    "                        y_ = y + y1 if 0 < y + y1 < 21 else (y + y1) % 21\n",
    "                        halites_pos[x + WINDOW_SIZE - 1][y + WINDOW_SIZE - 1] = halites[x_][y_]\n",
    "\n",
    "                for ship_id2, co_ord2 in ships.items():\n",
    "                    x1_dash, y1_dash = co_ord2\n",
    "                    ship_x = x1 - x1_dash + WINDOW_SIZE\n",
    "                    ship_y = y1 - y1_dash + WINDOW_SIZE\n",
    "                    ship_pos[ship_x][ship_y] = 1\n",
    "\n",
    "                for yard, yard_co_ord in yards.items():\n",
    "                    x1_dash, y1_dash = yard_co_ord\n",
    "                    yard_x = x1 - x1_dash + WINDOW_SIZE\n",
    "                    yard_y = y1 - y1_dash + WINDOW_SIZE\n",
    "                    yard_pos[yard_x][yard_y] = 1\n",
    "\n",
    "                state = torch.stack([halites_pos, ship_pos, yard_pos])\n",
    "                if ship_id in ship_states and len(my_action) > 0:\n",
    "                    prev_state = ship_states[ship_id]\n",
    "                    ship_states[ship_id] = state\n",
    "                    action = encoder.transform(my_action[ship_id])\n",
    "                    player = observation['player']\n",
    "                    reward = observation['players'][player][0]\n",
    "                    memory.push(\n",
    "                        prev_state, action, state, reward\n",
    "                    )\n",
    "                else:\n",
    "                    ship_states[ship_id] = state\n",
    "            step += 1\n",
    "        optimize_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n",
      "random move\n"
     ]
    }
   ],
   "source": [
    "train_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = memory.sample(6)\n",
    "\n",
    "batch = Transitions(*zip(*trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = memory.sample(1)[0].state.reshape(1, x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = sample.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(sample).argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
